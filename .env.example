# For Searxng search, defaults to http://localhost:8888
SEARXNG_URL=

# LLM Configuration (Ollama only)
LLM_MODEL=qwen3:4b                    # Model name in Ollama
OLLAMA_BASE_URL=http://localhost:11434/    # Ollama API endpoint

# Research Configuration
MAX_WEB_RESEARCH_LOOPS=3

# Development Configuration
# Set to 'true' to use mock LLM client instead of connecting to Ollama
# Useful for development and testing without running Ollama server
DEBUG=false